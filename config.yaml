# ==============================================
# Unified Hyperparameter Tuning Configuration
# Supports both Grid Search and Bayesian Search
# ==============================================

model:
  name: SLAI-Agent
  version: v1.6.2

run:
  id_prefix: "run"
  output_dir: "logs/"
  plots_dir: "plots/"

agent-network:
  adaptive:
    class: AdaptiveAgent
    path: src.agents.adaptive_agent
    learning_rate: 0.02
    exploration_rate: 0.2
    memory_capacity: 500
    replay_capacity: 100000
    priority_alpha: 0.6
    experience_staleness_days: 1
    per_beta: 0.4
    risk_threshold: 0.7

  alignment:
    class: AlignmentAgent
    path: src.agents.alignment_agent
    init_args:
      value_model: {}
      ethics: {}
      memory: {}
      sensitive_attrs: ["age", "gender"]
      monitor:
        class: AlignmentMonitor
        path: src.agents.alignment.alignment_monitor
        fairness_metrics:
          - demographic_parity
          - equal_opportunity
          - predictive_equality
        ethical_rules:
          privacy:
            - "No sharing of personally identifiable information (PII)"
          fairness:
            - "Avoid bias towards protected attributes like gender or race"
          transparency:
            - "Explain decisions if confidence is low"
        drift_threshold: 0.15
        audit_frequency: 1000
        adaptive_weights:
          fairness: 0.4
          ethics: 0.3
          safety: 0.3
      corrections: {}


  language:  
    class: LanguageAgent
    path: src.agents.language_agent
    init_args: {}
    llm: SLAILM()  
    history: []  
    summary: null  
    memory_limit: 1000  
    enable_summarization: true  
    summarizer: null
    readonly_wordlist: true
    disable_synonym_training: true

  knowledge:
    class: KnowledgeAgent
    path: src.agents.knowledge_agent
    init_args: {}
    cache_size: 1500
    similarity_threshold: 0.25
    ontology:
      max_depth: 3
      inherit_types: true
    rules:
      apply_during_retrieval: true

  learning:
    class: LearningAgent
    path: src.agents.learning_agent
    init_args:
      algorithm: dqn
      state_dim: 4
      action_dim: 2
      hidden_size: 128
    dqn:
      learning_rate: 0.001
      buffer_size: 10000
      batch_size: 64
    maml:
      type: maml
      class: MAMLAgent
      path: src.agents.learning.maml_rl
      state_size: 52
      action_size: 3
      hidden_size: 64
      meta_lr: 0.001
      inner_lr: 0.01
      gamma: 0.99
    rsi:
      type: rl
      class: RLAgent
      path: src.agents.learning.rl_agent
      learning_rate: 0.01
      discount_factor: 0.99
      epsilon: 0.1
    rl:
      type: rsi
      calss: RSI_Agent
      path: src.agents.learning.rsi
      target_update_frequency: 100
      state_size: 52
      action_size: 3
      shared_memory: null
    epsilon: 0.1
    discount: 0.95
    memory_limit: 50000
    learning_rate: 0.001
    optimized_mode': True
    network_size': 128
    max_task_pool': 50

  safety:
    class: SafeAI_Agent
    path: src.agents.safety_agent
    init_args:
      constitutional_rules:
        general: ["Do no harm", "Respect autonomy"]
        data: ["Avoid PII leakage"]
      risk_threshold:
        safety: 0.02
        privacy: 0.05
        security: 0.01
      audit_level: 3
      enable_rlhf: true

  perception:
    class: PerceptionAgent
    path: src.agents.perception_agent
    init_args:
      modalities:
        - vision
        - text
        - audio
      embed_dim: 100
      projection_dim: 256
      batch_size: 8
      learning_rate: 0.001
      epochs: 20

  planning:
    class: PlanningAgent
    path: src.agents.planning_agent
    init_args: {}

  evaluation:
    class: EvaluationAgent
    path: src.agents.evaluation_agent
    init_args:
      shared_memory: ${shared_memory}
      agent_factory: ${agent_factory}
    threshold: 0.9

  reasoning:
    class: ReasoningAgent
    path: src.agents.reasoning_agent
    init_args:
      tuple_key: "subject|predicate|object"
      storage_path: "src/agents/knowledge/knowledge_db.json"
      contradiction_threshold: 0.25       # Threshold for conflict detection
      rule_validation: 
        enable: true
        min_soundness_score: 0.7          # Minimum logical validity score
        max_circular_depth: 3             # Max allowed dependency depth
      nlp_integration:
        spacy_model: "en_core_web_lg"     # Replace regex parsing
        sentence_transformer: "all-MiniLM-L6-v2" # For semantic similarity
      serialization:
        persist_nlp_state: true           # Save word vectors/entity recognition
        compress_knowledge: true
      inference:
        default_chain_length: 5           # For multi-hop reasoning
        neuro_symbolic_weight: 0.4        # Balance between symbolic/neural
      limits:
        max_rules: 200                    # Prevent rule explosion
        max_hypotheses: 100               # Control graph traversal
      fallback:
        enable_llm_fallback: true         # Integrate with LanguageAgent
        llm_temperature: 0.3

training:
  num_samples: 500

# ==========================
# Hyperparameters Definition
# ==========================

hyperparameters:
  - name: learning_rate
    type: float
    min: 0.0001
    max: 0.1
    prior: log-uniform
    steps: 5

  - name: num_layers
    type: int
    min: 1
    max: 10
    step: 1

  - name: batch_size
    type: int
    min: 16
    max: 256
    step: 16

  - name: optimizer
    type: categorical
    choices: [adam, sgd, rmsprop]

  - name: activation
    type: categorical
    choices: [relu, tanh, sigmoid]

  - name: dropout_rate
    type: float
    min: 0.0
    max: 0.5
    steps: 6

  - name: gamma
    type: float
    min: 0.8
    max: 0.999
    steps: 5

  - name: num_qubits
    type: int
    min: 2
    max: 6
  - name: num_quantum_layers
    type: int
    min: 1
    max: 4

# ==========================
# Tuning Strategy Settings
# ==========================

tuning:
  strategy: bayesian         # options: bayesian, grid
  n_calls: 20                # used for Bayesian
  n_random_starts: 5         # used for Bayesian

configs:
  bayesian_config: "src/tuning/configs/bayesian_config.json"
  grid_config: "src/tuning/configs/grid_config.json"

# ==========================
# Thresholds and Alignment
# ==========================

alignment_thresholds:
  bias_threshold: 0.1
  reward_threshold: 70.0
  statistical_parity: 0.1
  equal_opportunity: 0.1
  predictive_parity: 0.1
  individual_fairness: 0.1

rollback:
  enabled: true
  strategy: "git_versioned"
  backup_dir: "models/backups/"

paths:
  models: "models/"


retrain:
  enabled: true
  trigger_on_violation: true

logging:
  log_file: "logs/app.log"
  level: INFO
  rotate: true
  max_size_mb: 50
  backup_count: 10

# ==========================
# Security Settings
# ==========================

security:
  encrypt_models: true
  enable_threat_detection: true
  adversarial_training: false
  backup_on_threat: true

# ==========================
# Data Autit
# ==========================

dataset_path: "data/dataset.csv"
config_path: "configs/config.yaml"
logs_path: "logs/"
audit_output_dir: "audits/"
processed_output_path: "data/processed_dataset.csv"

monitoring_weights:
  accuracy: 0.5
  f1_score: 0.3
  risk_score: 0.2

alert_thresholds:
  accuracy: 0.75
  risk_score: 0.25

security_policy:
  safe_ai:
    can_access_data: false
    can_modify_model: false
    can_export: false

  model_trainer:
    can_access_data: true
    can_modify_model: true
    can_export: true

# ==========================
# Compliance & Ethics
# ==========================
compliance:
  regulations:
    - GDPR
    - CCPA
  enable_audit: true
  anonymize_data: true
  consent_management: true

# ==========================
# Monitoring & Drift
# ==========================
monitoring:
  enable_monitoring: true
  drift_detection:
    enabled: true
    threshold: 0.05
  performance_monitoring:
    interval_seconds: 300  # 5 minutes
  alerting:
    enable_alerts: true
    alert_thresholds:
      performance_drop: 0.1
      bias_increase: 0.05

paths:
  data_source: "data/sample_dataset.csv"
