import os
import json
import pandas as pd
import numpy as np
from pathlib import Path
from collections import Counter
import matplotlib.pyplot as plt
import seaborn as sns
import langid

DATA_DIR = Path('../../data')
RAW_DIR = DATA_DIR / 'raw'
PROCESSED_DIR = DATA_DIR / 'processed'

PROCESSED_DIR.mkdir(parents=True, exist_ok=True)

def load_json(file_path):
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)

def save_json(data, file_path):
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2)

def load_dataset(dataset_name):
    processed_path = PROCESSED_DIR / f"{dataset_name}.json"
    raw_path = RAW_DIR / f"{dataset_name}.json"

    if processed_path.exists():
        return load_json(processed_path)
    elif raw_path.exists():
        raw_data = load_json(raw_path)
        processed_data = preprocess(raw_data)
        save_json(processed_data, processed_path)
        return processed_data
    else:
        raise FileNotFoundError(f"No dataset named {dataset_name} found.")
    
def clean_text(text):
    if not isinstance(text, str):
        return text
    return text.strip().lower().replace('\n', ' ')

def detect_language(text):
    lang, _ = langid.classify(text)
    return lang

def preprocess(data):
    if isinstance(data, list):
        return [clean_text(entry) for entry in data]
    elif isinstance(data, dict):
        return {k: clean_text(v) for k, v in data.items()}
    return data

def profile_data(data):
    lengths = [len(entry) for entry in data if isinstance(entry, str)]
    tokens = [len(entry.split()) for entry in data if isinstance(entry, str)]
    duplicates = len(data) - len(set(data))

    print(f"Total entries: {len(data)}")
    print(f"Average length: {np.mean(lengths):.2f}")
    print(f"Average tokens: {np.mean(tokens):.2f}")
    print(f"Duplicate entries: {duplicates}")

def visualize_distribution(data):
    lengths = [len(entry) for entry in data if isinstance(entry, str)]
    tokens = [len(entry.split()) for entry in data if isinstance(entry, str)]

    fig, axs = plt.subplots(1, 2, figsize=(12, 5))
    sns.histplot(lengths, bins=30, ax=axs[0])
    axs[0].set_title('Text Length Distribution')
    sns.histplot(tokens, bins=30, ax=axs[1])
    axs[1].set_title('Token Count Distribution')
    plt.show()

def language_stats(data):
    languages = [detect_language(entry) for entry in data if isinstance(entry, str)]
    lang_counts = Counter(languages)
    print("Language Distribution:")
    for lang, count in lang_counts.items():
        print(f"{lang}: {count}")

def save_as_parquet(data, filename):
    df = pd.DataFrame(data, columns=['text'])
    df.to_parquet(PROCESSED_DIR / f"{filename}.parquet", index=False)
